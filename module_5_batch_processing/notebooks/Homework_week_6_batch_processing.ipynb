{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abd80fa-4b06-4edc-b693-f7a03f4e95e0",
   "metadata": {},
   "source": [
    "- Name: Isaac Ndirangu Muturi\n",
    "- Email: ndirangumuturi749@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe64384-97f9-4816-ad60-d551896897ef",
   "metadata": {},
   "source": [
    "## Week 5 Homework \n",
    "\n",
    "For this homework we will be using the FHV 2019-10 data found here. [FHV Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4993b-4597-45dd-b93e-8595222c4eaa",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "\n",
    "> [!NOTE]\n",
    "> To install PySpark follow this [guide](https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/pyspark.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cf53b6-6ba0-4f56-8ad0-fded175cb5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/04 19:01:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd459720-1dca-483a-a698-cb412627f204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://de-zoomcamp.us-central1-c.c.direct-disk-412820.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f73d4423d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff6a40a-d68a-4b94-9da7-23eeabfd0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "source": [
    "print(pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4fee7d-be54-4661-8d74-68e22041d385",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**FHV October 2019**\n",
    "\n",
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 1MB\n",
    "- 6MB\n",
    "- 25MB\n",
    "- 87MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba6ff5f-5812-4832-aea0-1aa5e339bbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 19:04:48--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.112.3\n",
      "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T190448Z&X-Amz-Expires=300&X-Amz-Signature=9775d700250efeb7cd38589d3edeea30d4c84ee5d91339fbf0805ed0adbd7eb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 19:04:48--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T190448Z&X-Amz-Expires=300&X-Amz-Signature=9775d700250efeb7cd38589d3edeea30d4c84ee5d91339fbf0805ed0adbd7eb9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz.1’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-03-04 19:04:49 (129 MB/s) - ‘fhv_tripdata_2019-10.csv.gz.1’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56c803c-5ff2-4c5e-9d61-dc4e71ce26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -kf fhv_tripdata_2019-10.csv.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ffb3ad-e940-4b63-adf2-33378cf5df60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08e05b4-f6ab-4041-8659-06201d665b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "# Define the schema for FHV data\n",
    "fhv_schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0836f2-2faa-4d74-816b-cf99042585e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/04 19:20:11 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 6\n",
      "CSV file: file:///home/ndirangu749/Data_Engineering_Zoomcamp_2024/module_5_batch_processing/data/raw/fhv/2019/10/fhv_tripdata_2019-10.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "month = 10\n",
    "\n",
    "input_path = f'../data/raw/fhv/{year}/{month:02d}/'\n",
    "output_path = f'../data/pq/fhv/{year}/{month:02d}/'\n",
    "\n",
    "# Read FHV data with specified schema\n",
    "df_fhv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(fhv_schema) \\\n",
    "    .csv(input_path)\n",
    "\n",
    "# Repartition the DataFrame to 6 partitions and save it to parquet\n",
    "df_fhv \\\n",
    "    .repartition(6) \\\n",
    "    .write.parquet(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb72bc8-112d-41bc-b37d-56c39bc2885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/pq/fhv/2019/10/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d049c4ae-0ce6-4624-88e5-91dc9b6dfc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 36M\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749    0 Mar  4 19:20 _SUCCESS\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00000-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00001-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00002-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00003-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00004-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n",
      "-rw-r--r-- 1 ndirangu749 ndirangu749 6.0M Mar  4 19:20 part-00005-bda4c532-3691-4eee-a6bc-49d32df84646-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../data/pq/fhv/2019/10/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe154f9-10b0-44e2-b130-6635db2c7568",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records** \n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n",
    "Consider only trips that started on the 15th of October.\n",
    "\n",
    "- 108,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- 62,610\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Be aware of columns order when defining schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ddb635c-c18b-4eee-a8f5-eb53d2a9a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fhv = spark.read.parquet('../data/pq/fhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6e76696-3bbe-42a3-996b-f8cd5bc75e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B00628|2019-10-15 08:20:19|2019-10-15 09:30:40|         238|         132|   null|\n",
      "|              B03016|2019-10-15 15:47:56|2019-10-15 16:20:50|         264|          94|   null|\n",
      "|              B02930|2019-10-15 13:39:43|2019-10-15 13:44:54|         264|         185|   null|\n",
      "|              B03160|2019-10-15 17:30:00|2019-10-15 18:13:00|          51|          51|   null|\n",
      "|              B01800|2019-10-15 13:44:00|2019-10-15 16:04:00|         264|         264|   null|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_oct_15_trips = df_fhv.filter(col(\"pickup_datetime\").cast(\"date\") == \"2019-10-15\")\n",
    "df_oct_15_trips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2ac390b-8b88-4736-875a-b8777a6071bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taxi trips on the 15th of October: 62610\n"
     ]
    }
   ],
   "source": [
    "num_trips_oct_15 = df_oct_15_trips.count()\n",
    "\n",
    "print(\"Number of taxi trips on the 15th of October:\", num_trips_oct_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402b927-034b-4d8e-b3bd-1062d873fc11",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day** \n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?\n",
    "\n",
    "- 631,152.50 Hours\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a461e-8992-4b4a-8b18-30fc1e1e63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "\n",
    "# Calculate the duration of each trip in seconds\n",
    "df_fhv = df_fhv.withColumn(\"trip_duration_seconds\", (unix_timestamp(\"dropoff_datetime\") - unix_timestamp(\"pickup_datetime\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74888249-8078-4266-928c-92207ec1b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert duration to hours\n",
    "df_fhv = df_fhv.withColumn(\"trip_duration_hours\", col(\"trip_duration_seconds\") / 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6678adf-45da-4cf1-b454-d0f619255b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(max(trip_duration_hours)=631152.5)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find the Length of the longest trip in the dataset (in hours):\n",
    "# Find the maximum duration\n",
    "max_duration = df_fhv.agg({\"trip_duration_hours\": \"max\"}).collect()\n",
    "max_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3a691-f203-4e35-b795-06ad65cc3cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c693ea06-52df-4281-a178-33ceda34e8d7",
   "metadata": {},
   "source": [
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37933ce3-b083-400d-a674-cfab20b91b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c81e63-1010-4133-8aa7-41a2a3288b80",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Least frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Jamaica Bay\n",
    "- Union Sq\n",
    "- Crown Heights North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d494d9d-d3e3-47dc-b3c2-471ebde35a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(LocationID='1', Borough='EWR', Zone='Newark Airport', service_zone='EWR'),\n",
       " Row(LocationID='2', Borough='Queens', Zone='Jamaica Bay', service_zone='Boro Zone'),\n",
       " Row(LocationID='3', Borough='Bronx', Zone='Allerton/Pelham Gardens', service_zone='Boro Zone'),\n",
       " Row(LocationID='4', Borough='Manhattan', Zone='Alphabet City', service_zone='Yellow Zone'),\n",
       " Row(LocationID='5', Borough='Staten Island', Zone='Arden Heights', service_zone='Boro Zone')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the zone lookup data into a DataFrame\n",
    "zone_lookup_df = spark.read.option(\"header\", \"true\").csv(\"taxi+_zone_lookup.csv\")\n",
    "zone_lookup_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def197f-f6e6-4434-bae0-defbd1bb8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view for the zone lookup data\n",
    "zone_lookup_df.createOrReplaceTempView(\"zone_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a76aaf-4460-4c5a-a7ce-a43a67940a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+---------------------+-------------------+----------+-------------+--------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|trip_duration_seconds|trip_duration_hours|LocationID|      Borough|                Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+---------------------+-------------------+----------+-------------+--------------------+------------+\n",
      "|              B00706|2019-10-11 10:27:51|2019-10-11 10:45:37|          23|         221|   null|                 1066| 0.2961111111111111|        23|Staten Island|Bloomfield/Emerso...|   Boro Zone|\n",
      "|              B00256|2019-10-07 04:55:42|2019-10-07 05:14:21|         264|         264|   null|                 1119|0.31083333333333335|       264|      Unknown|                  NV|         N/A|\n",
      "|              B01730|2019-10-05 04:43:59|2019-10-05 05:15:55|         264|         223|   null|                 1916| 0.5322222222222223|       264|      Unknown|                  NV|         N/A|\n",
      "|              B00821|2019-10-19 18:55:12|2019-10-19 19:00:56|         264|          96|   null|                  344|0.09555555555555556|       264|      Unknown|                  NV|         N/A|\n",
      "|              B00706|2019-10-29 11:41:37|2019-10-29 11:53:18|         221|         172|   null|                  701| 0.1947222222222222|       221|Staten Island|           Stapleton|   Boro Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+---------------------+-------------------+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = df_fhv.join(zone_lookup_df, df_fhv.PULocationID == zone_lookup_df.LocationID)\n",
    "joined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fe6a8cb-40b0-432b-9369-647a380ea7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Zone|count|\n",
      "+--------------------+-----+\n",
      "|           Homecrest| 1295|\n",
      "|              Corona| 7175|\n",
      "|    Bensonhurst West| 1880|\n",
      "|         Westerleigh| 1317|\n",
      "|Charleston/Totten...| 2533|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each zone\n",
    "zone_counts = joined_df.groupBy(\"Zone\").count()\n",
    "zone_counts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "170bc29e-5104-4efd-b6db-86124a2ec524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Zone='Jamaica Bay', count=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the least frequent pickup location zone\n",
    "least_frequent_zone = zone_counts.orderBy(col(\"count\")).first()\n",
    "least_frequent_zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c536f2e-f24f-427a-a9cc-ca0627178950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
