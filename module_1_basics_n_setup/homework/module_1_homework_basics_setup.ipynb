{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67aaa08",
   "metadata": {},
   "source": [
    "- Name: Isaac Ndirangu Muturi\n",
    "- Email: ndirangumuturi749@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad10362",
   "metadata": {},
   "source": [
    "## Module 1 Homework\n",
    "\n",
    "## Docker & SQL\n",
    "\n",
    "In this homework we'll prepare the environment \n",
    "and practice with Docker and SQL\n",
    "\n",
    "\n",
    "## Question 1. Knowing docker tags\n",
    "\n",
    "Run the command to get information on Docker \n",
    "\n",
    "```docker --help```\n",
    "\n",
    "Now run the command to get help on the \"docker build\" command:\n",
    "\n",
    "```docker build --help```\n",
    "\n",
    "Do the same for \"docker run\".\n",
    "\n",
    "Which tag has the following text? - *Automatically remove the container when it exits* \n",
    "\n",
    "- `--delete`\n",
    "- `--rc`\n",
    "- `--rmc`\n",
    "- `--rm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --rm\n",
    "\n",
    "#   rm          Remove one or more containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98352312",
   "metadata": {},
   "source": [
    "## Question 2. Understanding docker first run \n",
    "\n",
    "Run docker with the python:3.9 image in an interactive mode and the entrypoint of bash.\n",
    "Now check the python modules that are installed ( use ```pip list``` ). \n",
    "\n",
    "What is version of the package *wheel* ?\n",
    "\n",
    "- 0.42.0\n",
    "- 1.0.0\n",
    "- 23.0.1\n",
    "- 58.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067faa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Python 3.9 image in interactive mode with bash as entrypoint\n",
    "docker run -it --entrypoint /bin/bash python:3.9\n",
    "\n",
    "# Inside the container, check the version of the 'wheel' package\n",
    "pip list | grep wheel\n",
    "\n",
    "\n",
    "# (base) ndirangu749@envy15:~/ZOOMCAMP/Data_Engineering_Zoomcamp_2024/week_1_basics_n_setup/homework$ docker run -it --entrypoint /bin/bash python:3.9\n",
    "# root@03a78c698bd1:/# pip list\n",
    "# Package    Version\n",
    "# ---------- -------\n",
    "# pip        23.0.1\n",
    "# setuptools 58.1.0\n",
    "# wheel      0.40.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab1118",
   "metadata": {},
   "source": [
    "\n",
    "# Prepare Postgres\n",
    "\n",
    "Run Postgres and load data as shown in the videos\n",
    "We'll use the green taxi trips from September 2019:\n",
    "\n",
    "```wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz```\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "```wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv```\n",
    "\n",
    "Download this data and put it into Postgres (with jupyter notebooks or with a pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to upload_data_green_taxi.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6318941",
   "metadata": {},
   "source": [
    "## Question 3. Count records \n",
    "\n",
    "How many taxi trips were totally made on September 18th 2019?\n",
    "\n",
    "Tip: started and finished on 2019-09-18. \n",
    "\n",
    "Remember that `lpep_pickup_datetime` and `lpep_dropoff_datetime` columns are in the format timestamp (date and hour+min+sec) and not in date.\n",
    "\n",
    "- 15767\n",
    "- 15612\n",
    "- 15859\n",
    "- 89009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT COUNT(*)\n",
    "FROM green_taxi_data\n",
    "WHERE DATE(lpep_pickup_datetime) = '2019-09-18'\n",
    "  AND DATE(lpep_dropoff_datetime) = '2019-09-18';\n",
    "\n",
    "# 15612"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046b614",
   "metadata": {},
   "source": [
    "## Question 4. Longest trip for each day\n",
    "\n",
    "Which was the pick up day with the longest trip distance?\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "Tip: For every trip on a single day, we only care about the trip with the longest distance. \n",
    "\n",
    "- 2019-09-18\n",
    "- 2019-09-16\n",
    "- 2019-09-26\n",
    "- 2019-09-21\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb981f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "  lpep_pickup_datetime::DATE AS pickup_day,\n",
    "  MAX(trip_distance) AS longest_trip_distance\n",
    "FROM\n",
    "  green_taxi_data\n",
    "GROUP BY\n",
    "  lpep_pickup_datetime::DATE\n",
    "ORDER BY\n",
    "  longest_trip_distance DESC\n",
    "LIMIT 1;\n",
    "\n",
    "# 2019-09-26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08985b",
   "metadata": {},
   "source": [
    "## Question 5. Three biggest pick up Boroughs\n",
    "\n",
    "Consider lpep_pickup_datetime in '2019-09-18' and ignoring Borough has Unknown\n",
    "\n",
    "Which were the 3 pick up Boroughs that had a sum of total_amount superior to 50000?\n",
    " \n",
    "- \"Brooklyn\" \"Manhattan\" \"Queens\"\n",
    "- \"Bronx\" \"Brooklyn\" \"Manhattan\"\n",
    "- \"Bronx\" \"Manhattan\" \"Queens\" \n",
    "- \"Brooklyn\" \"Queens\" \"Staten Island\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT\n",
    "  \"zones\".\"Borough\",\n",
    "  SUM(\"green_taxi_data\".\"total_amount\") AS total_amount_sum\n",
    "FROM\n",
    "  \"green_taxi_data\"\n",
    "JOIN\n",
    "  \"zones\" ON \"green_taxi_data\".\"PULocationID\" = \"zones\".\"LocationID\"\n",
    "WHERE\n",
    "  \"green_taxi_data\".\"lpep_pickup_datetime\"::DATE = '2019-09-18'\n",
    "  AND \"green_taxi_data\".\"PULocationID\" IS NOT NULL\n",
    "GROUP BY\n",
    "  \"zones\".\"Borough\"\n",
    "HAVING\n",
    "  SUM(\"green_taxi_data\".\"total_amount\") > 50000\n",
    "ORDER BY\n",
    "  total_amount_sum DESC\n",
    "LIMIT 3;\n",
    "\n",
    "# \"Brooklyn\"\n",
    "# \"Manhattan\"\n",
    "# \"Queens\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0688f711",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6. Largest tip\n",
    "\n",
    "For the passengers picked up in September 2019 in the zone name Astoria which was the drop off zone that had the largest tip?\n",
    "We want the name of the zone, not the id.\n",
    "\n",
    "Note: it's not a typo, it's `tip` , not `trip`\n",
    "\n",
    "- Central Park\n",
    "- Jamaica\n",
    "- JFK Airport\n",
    "- Long Island City/Queens Plaza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025638e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WITH AstoriaPickups AS (\n",
    "  SELECT\n",
    "    \"DOLocationID\",\n",
    "    MAX(\"tip_amount\") AS max_tip\n",
    "  FROM\n",
    "    \"green_taxi_data\"\n",
    "  JOIN\n",
    "    \"zones\" ON \"green_taxi_data\".\"PULocationID\" = \"zones\".\"LocationID\"\n",
    "  WHERE\n",
    "    \"zones\".\"Zone\" = 'Astoria'\n",
    "    AND EXTRACT(YEAR FROM \"lpep_pickup_datetime\") = 2019\n",
    "    AND EXTRACT(MONTH FROM \"lpep_pickup_datetime\") = 9\n",
    "  GROUP BY\n",
    "    \"DOLocationID\"\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  \"zones\".\"Zone\"\n",
    "FROM\n",
    "  \"zones\"\n",
    "JOIN\n",
    "  AstoriaPickups ON \"zones\".\"LocationID\" = AstoriaPickups.\"DOLocationID\"\n",
    "WHERE\n",
    "  \"zones\".\"Zone\" IS NOT NULL\n",
    "ORDER BY\n",
    "  AstoriaPickups.max_tip DESC\n",
    "LIMIT 1;\n",
    "\n",
    "# JFK Airport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35735d49",
   "metadata": {},
   "source": [
    "## Terraform\n",
    "\n",
    "In this section homework we'll prepare the environment by creating resources in GCP with Terraform.\n",
    "\n",
    "In your VM on GCP/Laptop/GitHub Codespace install Terraform. \n",
    "Copy the files from the course repo\n",
    "[here](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/01-docker-terraform/1_terraform_gcp/terraform) to your VM/Laptop/GitHub Codespace.\n",
    "\n",
    "Modify the files as necessary to create a GCP Bucket and Big Query Dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce63075",
   "metadata": {},
   "source": [
    "## Question 7. Creating Resources\n",
    "\n",
    "After updating the main.tf and variable.tf files run:\n",
    "\n",
    "```\n",
    "terraform apply\n",
    "```\n",
    "\n",
    "Paste the output of this command into the homework submission form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5645e",
   "metadata": {},
   "source": [
    "(base) ndirangu749@envy15:~/ZOOMCAMP/Data_Engineering_Zoomcamp_2024/week_1_basics_n_setup/homework$ terraform init\n",
    "\n",
    "Initializing the backend...\n",
    "\n",
    "Initializing provider plugins...\n",
    "- Finding hashicorp/google versions matching \"5.14.0\"...\n",
    "- Installing hashicorp/google v5.14.0...\n",
    "- Installed hashicorp/google v5.14.0 (signed by HashiCorp)\n",
    "\n",
    "Terraform has created a lock file .terraform.lock.hcl to record the provider\n",
    "selections it made above. Include this file in your version control repository\n",
    "so that Terraform can guarantee to make the same selections by default when\n",
    "you run \"terraform init\" in the future.\n",
    "\n",
    "Terraform has been successfully initialized!\n",
    "\n",
    "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
    "any changes that are required for your infrastructure. All Terraform commands\n",
    "should now work.\n",
    "\n",
    "If you ever set or change modules or backend configuration for Terraform,\n",
    "rerun this command to reinitialize your working directory. If you forget, other\n",
    "commands will detect it and remind you to do so if necessary.\n",
    "(base) ndirangu749@envy15:~/ZOOMCAMP/Data_Engineering_Zoomcamp_2024/week_1_basics_n_setup/homework$ terraform plan\n",
    "\n",
    "Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following\n",
    "symbols:\n",
    "  + create\n",
    "\n",
    "Terraform will perform the following actions:\n",
    "\n",
    "  # google_bigquery_dataset.demo_dataset will be created\n",
    "  + resource \"google_bigquery_dataset\" \"demo_dataset\" {\n",
    "      + creation_time              = (known after apply)\n",
    "      + dataset_id                 = \"demo_dataset\"\n",
    "      + default_collation          = (known after apply)\n",
    "      + delete_contents_on_destroy = false\n",
    "      + effective_labels           = (known after apply)\n",
    "      + etag                       = (known after apply)\n",
    "      + id                         = (known after apply)\n",
    "      + is_case_insensitive        = (known after apply)\n",
    "      + last_modified_time         = (known after apply)\n",
    "      + location                   = \"europe-north1\"\n",
    "      + max_time_travel_hours      = (known after apply)\n",
    "      + project                    = \"direct-disk-412820\"\n",
    "      + self_link                  = (known after apply)\n",
    "      + storage_billing_model      = (known after apply)\n",
    "      + terraform_labels           = (known after apply)\n",
    "    }\n",
    "\n",
    "  # google_storage_bucket.demo-bucket will be created\n",
    "  + resource \"google_storage_bucket\" \"demo-bucket\" {\n",
    "      + effective_labels            = (known after apply)\n",
    "      + force_destroy               = true\n",
    "      + id                          = (known after apply)\n",
    "      + location                    = \"EUROPE-NORTH1\"\n",
    "      + name                        = \"direct-disk-412820-terra-bucket\"\n",
    "      + project                     = (known after apply)\n",
    "      + public_access_prevention    = (known after apply)\n",
    "      + rpo                         = (known after apply)\n",
    "      + self_link                   = (known after apply)\n",
    "      + storage_class               = \"STANDARD\"\n",
    "      + terraform_labels            = (known after apply)\n",
    "      + uniform_bucket_level_access = (known after apply)\n",
    "      + url                         = (known after apply)\n",
    "\n",
    "      + lifecycle_rule {\n",
    "          + action {\n",
    "              + type = \"AbortIncompleteMultipartUpload\"\n",
    "            }\n",
    "          + condition {\n",
    "              + age                   = 1\n",
    "              + matches_prefix        = []\n",
    "              + matches_storage_class = []\n",
    "              + matches_suffix        = []\n",
    "              + with_state            = (known after apply)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "Plan: 2 to add, 0 to change, 0 to destroy.\n",
    "\n",
    "──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "Note: You didn't use the -out option to save this plan, so Terraform can't guarantee to take exactly these actions if you run\n",
    "\"terraform apply\" now.\n",
    "(base) ndirangu749@envy15:~/ZOOMCAMP/Data_Engineering_Zoomcamp_2024/week_1_basics_n_setup/homework$ terraform apply\n",
    "\n",
    "Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following\n",
    "symbols:\n",
    "  + create\n",
    "\n",
    "Terraform will perform the following actions:\n",
    "\n",
    "  # google_bigquery_dataset.demo_dataset will be created\n",
    "  + resource \"google_bigquery_dataset\" \"demo_dataset\" {\n",
    "      + creation_time              = (known after apply)\n",
    "      + dataset_id                 = \"demo_dataset\"\n",
    "      + default_collation          = (known after apply)\n",
    "      + delete_contents_on_destroy = false\n",
    "      + effective_labels           = (known after apply)\n",
    "      + etag                       = (known after apply)\n",
    "      + id                         = (known after apply)\n",
    "      + is_case_insensitive        = (known after apply)\n",
    "      + last_modified_time         = (known after apply)\n",
    "      + location                   = \"europe-north1\"\n",
    "      + max_time_travel_hours      = (known after apply)\n",
    "      + project                    = \"direct-disk-412820\"\n",
    "      + self_link                  = (known after apply)\n",
    "      + storage_billing_model      = (known after apply)\n",
    "      + terraform_labels           = (known after apply)\n",
    "    }\n",
    "\n",
    "  # google_storage_bucket.demo-bucket will be created\n",
    "  + resource \"google_storage_bucket\" \"demo-bucket\" {\n",
    "      + effective_labels            = (known after apply)\n",
    "      + force_destroy               = true\n",
    "      + id                          = (known after apply)\n",
    "      + location                    = \"EUROPE-NORTH1\"\n",
    "      + name                        = \"direct-disk-412820-terra-bucket\"\n",
    "      + project                     = (known after apply)\n",
    "      + public_access_prevention    = (known after apply)\n",
    "      + rpo                         = (known after apply)\n",
    "      + self_link                   = (known after apply)\n",
    "      + storage_class               = \"STANDARD\"\n",
    "      + terraform_labels            = (known after apply)\n",
    "      + uniform_bucket_level_access = (known after apply)\n",
    "      + url                         = (known after apply)\n",
    "\n",
    "      + lifecycle_rule {\n",
    "          + action {\n",
    "              + type = \"AbortIncompleteMultipartUpload\"\n",
    "            }\n",
    "          + condition {\n",
    "              + age                   = 1\n",
    "              + matches_prefix        = []\n",
    "              + matches_storage_class = []\n",
    "              + matches_suffix        = []\n",
    "              + with_state            = (known after apply)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "Plan: 2 to add, 0 to change, 0 to destroy.\n",
    "\n",
    "Do you want to perform these actions?\n",
    "  Terraform will perform the actions described above.\n",
    "  Only 'yes' will be accepted to approve.\n",
    "\n",
    "  Enter a value: yes\n",
    "\n",
    "google_bigquery_dataset.demo_dataset: Creating...\n",
    "google_storage_bucket.demo-bucket: Creating...\n",
    "google_bigquery_dataset.demo_dataset: Creation complete after 3s [id=projects/direct-disk-412820/datasets/demo_dataset]\n",
    "google_storage_bucket.demo-bucket: Creation complete after 4s [id=direct-disk-412820-terra-bucket]\n",
    "\n",
    "Apply complete! Resources: 2 added, 0 changed, 0 destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f97581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
